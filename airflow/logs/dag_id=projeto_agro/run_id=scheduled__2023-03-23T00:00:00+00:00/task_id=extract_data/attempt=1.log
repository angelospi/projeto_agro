[2023-03-27T03:12:17.997+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: projeto_agro.extract_data scheduled__2023-03-23T00:00:00+00:00 [queued]>
[2023-03-27T03:12:18.006+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: projeto_agro.extract_data scheduled__2023-03-23T00:00:00+00:00 [queued]>
[2023-03-27T03:12:18.006+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T03:12:18.006+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 1
[2023-03-27T03:12:18.007+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T03:12:18.018+0000] {taskinstance.py:1304} INFO - Executing <Task(PythonOperator): extract_data> on 2023-03-23 00:00:00+00:00
[2023-03-27T03:12:18.024+0000] {standard_task_runner.py:55} INFO - Started process 171 to run task
[2023-03-27T03:12:18.026+0000] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'projeto_agro', 'extract_data', 'scheduled__2023-03-23T00:00:00+00:00', '--job-id', '87', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmphk_ex83e']
[2023-03-27T03:12:18.027+0000] {standard_task_runner.py:83} INFO - Job 87: Subtask extract_data
[2023-03-27T03:12:18.090+0000] {task_command.py:389} INFO - Running <TaskInstance: projeto_agro.extract_data scheduled__2023-03-23T00:00:00+00:00 [running]> on host 264f1e537a4a
[2023-03-27T03:12:18.246+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=projeto_agro
AIRFLOW_CTX_TASK_ID=extract_data
AIRFLOW_CTX_EXECUTION_DATE=2023-03-23T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-23T00:00:00+00:00
[2023-03-27T03:12:33.065+0000] {logging_mixin.py:137} WARNING - /opt/airflow/dags/../../scripts/extract.py:27 DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.
[2023-03-27T03:12:36.728+0000] {_metadata.py:99} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: timed out
[2023-03-27T03:12:36.792+0000] {_metadata.py:99} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 113] No route to host
[2023-03-27T03:12:39.795+0000] {_metadata.py:99} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: timed out
[2023-03-27T03:12:39.796+0000] {_default.py:296} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2023-03-27T03:12:39.819+0000] {_metadata.py:154} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efca654d7c0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-03-27T03:12:39.852+0000] {_metadata.py:154} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efca654db20>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-03-27T03:12:39.892+0000] {_metadata.py:154} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efca656c0d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-03-27T03:12:39.932+0000] {_metadata.py:154} WARNING - Compute Engine Metadata server unavailable on attempt 4 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efca656c460>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-03-27T03:12:39.972+0000] {_metadata.py:154} WARNING - Compute Engine Metadata server unavailable on attempt 5 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efca656c8e0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
[2023-03-27T03:12:41.332+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/main.py", line 16, in extract
    extract.save_data_raw()
  File "/opt/airflow/dags/../../scripts/extract.py", line 36, in save_data_raw
    self.all_data_faostat.to_csv('gs://data_raw_area_project_agro/' + path_file_faostat)
  File "/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/pandas/io/formats/format.py", line 1189, in to_csv
    csv_formatter.save()
  File "/usr/local/lib/python3.9/site-packages/pandas/io/formats/csvs.py", line 261, in save
    self._save()
  File "/usr/local/lib/python3.9/site-packages/pandas/io/formats/csvs.py", line 266, in _save
    self._save_body()
  File "/usr/local/lib/python3.9/site-packages/pandas/io/formats/csvs.py", line 304, in _save_body
    self._save_chunk(start_i, end_i)
  File "/usr/local/lib/python3.9/site-packages/pandas/io/formats/csvs.py", line 315, in _save_chunk
    libwriters.write_csv_rows(
  File "pandas/_libs/writers.pyx", line 55, in pandas._libs.writers.write_csv_rows
  File "/usr/local/lib/python3.9/site-packages/fsspec/spec.py", line 1616, in write
    self.flush()
  File "/usr/local/lib/python3.9/site-packages/fsspec/spec.py", line 1652, in flush
    self._initiate_upload()
  File "/usr/local/lib/python3.9/site-packages/gcsfs/core.py", line 1592, in _initiate_upload
    self.location = sync(
  File "/usr/local/lib/python3.9/site-packages/fsspec/asyn.py", line 100, in sync
    raise return_result
  File "/usr/local/lib/python3.9/site-packages/fsspec/asyn.py", line 55, in _runner
    result[0] = await coro
  File "/usr/local/lib/python3.9/site-packages/gcsfs/core.py", line 1708, in initiate_upload
    headers, _ = await fs._call(
  File "/usr/local/lib/python3.9/site-packages/gcsfs/core.py", line 418, in _call
    status, headers, info, contents = await self._request(
  File "/usr/local/lib/python3.9/site-packages/decorator.py", line 221, in fun
    return await caller(func, *(extras + args), **kw)
  File "/usr/local/lib/python3.9/site-packages/gcsfs/retry.py", line 114, in retry_request
    return await func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/gcsfs/core.py", line 411, in _request
    validate_response(status, contents, path, args)
  File "/usr/local/lib/python3.9/site-packages/gcsfs/retry.py", line 83, in validate_response
    raise FileNotFoundError(path)
FileNotFoundError: https://storage.googleapis.com/upload/storage/v1/b/data_raw_area_project_agro/o
[2023-03-27T03:12:41.347+0000] {taskinstance.py:1322} INFO - Marking task as FAILED. dag_id=projeto_agro, task_id=extract_data, execution_date=20230323T000000, start_date=20230327T031217, end_date=20230327T031241
[2023-03-27T03:12:41.364+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 87 for task extract_data (https://storage.googleapis.com/upload/storage/v1/b/data_raw_area_project_agro/o; 171)
[2023-03-27T03:12:41.424+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-03-27T03:12:41.440+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
